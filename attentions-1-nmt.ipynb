{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-15T13:49:48.549214Z","iopub.execute_input":"2023-10-15T13:49:48.549544Z","iopub.status.idle":"2023-10-15T13:49:48.879824Z","shell.execute_reply.started":"2023-10-15T13:49:48.549516Z","shell.execute_reply":"2023-10-15T13:49:48.878876Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/hinge-english-to-hinglish-machine-translation/no_label.csv\n/kaggle/input/hinge-english-to-hinglish-machine-translation/synthetic-dataset/valid.csv\n/kaggle/input/hinge-english-to-hinglish-machine-translation/synthetic-dataset/train.csv\n/kaggle/input/hinge-english-to-hinglish-machine-translation/synthetic-dataset/.ipynb_checkpoints/train-checkpoint.csv\n/kaggle/input/hinge-english-to-hinglish-machine-translation/human-generated-dataset/valid_human_generated.pkl\n/kaggle/input/hinge-english-to-hinglish-machine-translation/human-generated-dataset/train_human_generated.pkl\n/kaggle/input/hinglish-top-dataset/Synthetically Generated Data/train.tsv\n/kaggle/input/hinglish-top-dataset/Human Annotated Data/test.tsv\n/kaggle/input/hinglish-top-dataset/Human Annotated Data/train.tsv\n/kaggle/input/hinglish-top-dataset/Human Annotated Data/validation.tsv\n/kaggle/input/language-translation-englishfrench/eng_-french.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd \nfrom __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:49:49.177692Z","iopub.execute_input":"2023-10-15T13:49:49.178922Z","iopub.status.idle":"2023-10-15T13:49:52.847035Z","shell.execute_reply.started":"2023-10-15T13:49:49.178885Z","shell.execute_reply":"2023-10-15T13:49:52.846106Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/hinglish-top-dataset/Synthetically Generated Data/train.tsv',sep='\\t')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:19.491795Z","iopub.execute_input":"2023-10-15T13:50:19.492412Z","iopub.status.idle":"2023-10-15T13:50:20.457878Z","shell.execute_reply.started":"2023-10-15T13:50:19.492368Z","shell.execute_reply":"2023-10-15T13:50:20.456963Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                            en_query  \\\n0  Who is the featured performer at The Grand Ole...   \n1                   Remind me of my meeting at 12 am   \n2                              set an alarm for 5 am   \n3    What ’ s will weather be like at Sydney at 2 pm   \n4                    What is the weather in Canada ?   \n\n                                            cs_query  \\\n0  Is Saturday night The Grand Ole Opry me featur...   \n1  mujhe 12 am ko meri meeting ke baare me yaad d...   \n2            subha 5 baje ke liye ek alarm set karen   \n3         dopaher 2 baje Sydney me mausam kaisa hoga   \n4                       Canada me mausam kaisa hai ?   \n\n                                           en_parses  \\\n0  [IN:GET_EVENT Who is [SL:CATEGORY_EVENT the fe...   \n1  [IN:CREATE_REMINDER Remind [SL:PERSON_REMINDED...   \n2  [IN:CREATE_ALARM set an alarm [SL:DATE_TIME fo...   \n3  [IN:GET_WEATHER What ’s will weather be like a...   \n4  [IN:GET_WEATHER What is the weather in [SL:LOC...   \n\n                                           cs_parses  \n0  [IN:GET_EVENT [SL:DATE_TIME Is Saturday night ...  \n1  [IN:CREATE_REMINDER [SL:PERSON_REMINDED mujhe ...  \n2  [IN:CREATE_ALARM [SL:DATE_TIME subha 5 baje ke...  \n3  [IN:GET_WEATHER [SL:DATE_TIME dopaher 2 baje ]...  \n4  [IN:GET_WEATHER [SL:LOCATION Canada ] me mausa...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en_query</th>\n      <th>cs_query</th>\n      <th>en_parses</th>\n      <th>cs_parses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Who is the featured performer at The Grand Ole...</td>\n      <td>Is Saturday night The Grand Ole Opry me featur...</td>\n      <td>[IN:GET_EVENT Who is [SL:CATEGORY_EVENT the fe...</td>\n      <td>[IN:GET_EVENT [SL:DATE_TIME Is Saturday night ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Remind me of my meeting at 12 am</td>\n      <td>mujhe 12 am ko meri meeting ke baare me yaad d...</td>\n      <td>[IN:CREATE_REMINDER Remind [SL:PERSON_REMINDED...</td>\n      <td>[IN:CREATE_REMINDER [SL:PERSON_REMINDED mujhe ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>set an alarm for 5 am</td>\n      <td>subha 5 baje ke liye ek alarm set karen</td>\n      <td>[IN:CREATE_ALARM set an alarm [SL:DATE_TIME fo...</td>\n      <td>[IN:CREATE_ALARM [SL:DATE_TIME subha 5 baje ke...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What ’ s will weather be like at Sydney at 2 pm</td>\n      <td>dopaher 2 baje Sydney me mausam kaisa hoga</td>\n      <td>[IN:GET_WEATHER What ’s will weather be like a...</td>\n      <td>[IN:GET_WEATHER [SL:DATE_TIME dopaher 2 baje ]...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What is the weather in Canada ?</td>\n      <td>Canada me mausam kaisa hai ?</td>\n      <td>[IN:GET_WEATHER What is the weather in [SL:LOC...</td>\n      <td>[IN:GET_WEATHER [SL:LOCATION Canada ] me mausa...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:20.459482Z","iopub.execute_input":"2023-10-15T13:50:20.460469Z","iopub.status.idle":"2023-10-15T13:50:20.471880Z","shell.execute_reply.started":"2023-10-15T13:50:20.460436Z","shell.execute_reply":"2023-10-15T13:50:20.470617Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                 en_query  \\\n0       Who is the featured performer at The Grand Ole...   \n1                        Remind me of my meeting at 12 am   \n2                                   set an alarm for 5 am   \n3         What ’ s will weather be like at Sydney at 2 pm   \n4                         What is the weather in Canada ?   \n...                                                   ...   \n170078              How many miles from Humble to Brenham   \n170079            What is traffic so bad on Ronald Reagan   \n170080           Concerts by The Strokes for this weekend   \n170081    How many mm of rain do we expect for tomorrow ?   \n170082                                  cancel all alarms   \n\n                                                 cs_query  \\\n0       Is Saturday night The Grand Ole Opry me featur...   \n1       mujhe 12 am ko meri meeting ke baare me yaad d...   \n2                 subha 5 baje ke liye ek alarm set karen   \n3              dopaher 2 baje Sydney me mausam kaisa hoga   \n4                            Canada me mausam kaisa hai ?   \n...                                                   ...   \n170078              Humble se Brenham tak kitne miles hai   \n170079          Ronald Reagan par traffic kyu kharaab hai   \n170080       Is weekend The Strokes ke hone wale Concerts   \n170081               kal kitni mm baarish ki ummeed hai ?   \n170082                            sarey alarms cance kare   \n\n                                                en_parses  \\\n0       [IN:GET_EVENT Who is [SL:CATEGORY_EVENT the fe...   \n1       [IN:CREATE_REMINDER Remind [SL:PERSON_REMINDED...   \n2       [IN:CREATE_ALARM set an alarm [SL:DATE_TIME fo...   \n3       [IN:GET_WEATHER What ’s will weather be like a...   \n4       [IN:GET_WEATHER What is the weather in [SL:LOC...   \n...                                                   ...   \n170078  [IN:GET_DISTANCE How many [SL:UNIT_DISTANCE mi...   \n170079  [IN:GET_INFO_TRAFFIC What is traffic so bad on...   \n170080  [IN:GET_EVENT [SL:CATEGORY_EVENT Concerts ] by...   \n170081  [IN:UNSUPPORTED_WEATHER How many mm of [SL:WEA...   \n170082  [IN:DELETE_ALARM cancel [SL:AMOUNT all ] alarms ]   \n\n                                                cs_parses  \n0       [IN:GET_EVENT [SL:DATE_TIME Is Saturday night ...  \n1       [IN:CREATE_REMINDER [SL:PERSON_REMINDED mujhe ...  \n2       [IN:CREATE_ALARM [SL:DATE_TIME subha 5 baje ke...  \n3       [IN:GET_WEATHER [SL:DATE_TIME dopaher 2 baje ]...  \n4       [IN:GET_WEATHER [SL:LOCATION Canada ] me mausa...  \n...                                                   ...  \n170078  [IN:GET_DISTANCE [SL:SOURCE Humble ] se [SL:DE...  \n170079  [IN:GET_INFO_TRAFFIC [SL:LOCATION Ronald Reaga...  \n170080  [IN:GET_EVENT [SL:DATE_TIME Is weekend ] [SL:N...  \n170081  [IN:UNSUPPORTED_WEATHER kal kitni mm [SL:WEATH...  \n170082  [IN:DELETE_ALARM [SL:AMOUNT sarey ] alarms can...  \n\n[170083 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>en_query</th>\n      <th>cs_query</th>\n      <th>en_parses</th>\n      <th>cs_parses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Who is the featured performer at The Grand Ole...</td>\n      <td>Is Saturday night The Grand Ole Opry me featur...</td>\n      <td>[IN:GET_EVENT Who is [SL:CATEGORY_EVENT the fe...</td>\n      <td>[IN:GET_EVENT [SL:DATE_TIME Is Saturday night ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Remind me of my meeting at 12 am</td>\n      <td>mujhe 12 am ko meri meeting ke baare me yaad d...</td>\n      <td>[IN:CREATE_REMINDER Remind [SL:PERSON_REMINDED...</td>\n      <td>[IN:CREATE_REMINDER [SL:PERSON_REMINDED mujhe ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>set an alarm for 5 am</td>\n      <td>subha 5 baje ke liye ek alarm set karen</td>\n      <td>[IN:CREATE_ALARM set an alarm [SL:DATE_TIME fo...</td>\n      <td>[IN:CREATE_ALARM [SL:DATE_TIME subha 5 baje ke...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What ’ s will weather be like at Sydney at 2 pm</td>\n      <td>dopaher 2 baje Sydney me mausam kaisa hoga</td>\n      <td>[IN:GET_WEATHER What ’s will weather be like a...</td>\n      <td>[IN:GET_WEATHER [SL:DATE_TIME dopaher 2 baje ]...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What is the weather in Canada ?</td>\n      <td>Canada me mausam kaisa hai ?</td>\n      <td>[IN:GET_WEATHER What is the weather in [SL:LOC...</td>\n      <td>[IN:GET_WEATHER [SL:LOCATION Canada ] me mausa...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>170078</th>\n      <td>How many miles from Humble to Brenham</td>\n      <td>Humble se Brenham tak kitne miles hai</td>\n      <td>[IN:GET_DISTANCE How many [SL:UNIT_DISTANCE mi...</td>\n      <td>[IN:GET_DISTANCE [SL:SOURCE Humble ] se [SL:DE...</td>\n    </tr>\n    <tr>\n      <th>170079</th>\n      <td>What is traffic so bad on Ronald Reagan</td>\n      <td>Ronald Reagan par traffic kyu kharaab hai</td>\n      <td>[IN:GET_INFO_TRAFFIC What is traffic so bad on...</td>\n      <td>[IN:GET_INFO_TRAFFIC [SL:LOCATION Ronald Reaga...</td>\n    </tr>\n    <tr>\n      <th>170080</th>\n      <td>Concerts by The Strokes for this weekend</td>\n      <td>Is weekend The Strokes ke hone wale Concerts</td>\n      <td>[IN:GET_EVENT [SL:CATEGORY_EVENT Concerts ] by...</td>\n      <td>[IN:GET_EVENT [SL:DATE_TIME Is weekend ] [SL:N...</td>\n    </tr>\n    <tr>\n      <th>170081</th>\n      <td>How many mm of rain do we expect for tomorrow ?</td>\n      <td>kal kitni mm baarish ki ummeed hai ?</td>\n      <td>[IN:UNSUPPORTED_WEATHER How many mm of [SL:WEA...</td>\n      <td>[IN:UNSUPPORTED_WEATHER kal kitni mm [SL:WEATH...</td>\n    </tr>\n    <tr>\n      <th>170082</th>\n      <td>cancel all alarms</td>\n      <td>sarey alarms cance kare</td>\n      <td>[IN:DELETE_ALARM cancel [SL:AMOUNT all ] alarms ]</td>\n      <td>[IN:DELETE_ALARM [SL:AMOUNT sarey ] alarms can...</td>\n    </tr>\n  </tbody>\n</table>\n<p>170083 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data=data[:50000]","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:20.773091Z","iopub.execute_input":"2023-10-15T13:50:20.773393Z","iopub.status.idle":"2023-10-15T13:50:20.778104Z","shell.execute_reply.started":"2023-10-15T13:50:20.773369Z","shell.execute_reply":"2023-10-15T13:50:20.776998Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"SOS_token = 0\nEOS_token = 1\nUNK_token=2\nclass Lang:\n    def __init__(self,name):\n        self.name=name\n        self.word2index={}\n        self.word2count={}\n        self.index2word={0:'sos',1:'eos','unk':2}\n        self.n_words=2\n    def addSentence(self,sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n            \n    def addWord(self,word):\n        if word not in self.word2index:\n            self.word2index[word]=self.n_words\n            self.word2count[word]=1\n            self.index2word[self.n_words]=word\n            self.n_words+=1\n        else:\n            self.word2count[word]+=1\n            ","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:22.164501Z","iopub.execute_input":"2023-10-15T13:50:22.164841Z","iopub.status.idle":"2023-10-15T13:50:22.171343Z","shell.execute_reply.started":"2023-10-15T13:50:22.164815Z","shell.execute_reply":"2023-10-15T13:50:22.170420Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    #s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n    return s.strip()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:22.940044Z","iopub.execute_input":"2023-10-15T13:50:22.940734Z","iopub.status.idle":"2023-10-15T13:50:22.946509Z","shell.execute_reply.started":"2023-10-15T13:50:22.940701Z","shell.execute_reply":"2023-10-15T13:50:22.945399Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def readLangs(lines,lang1,lang2,reverse=False):\n    print('Preparing Vocabulary.......')    \n    pairs=[[normalizeString(s) for s in l.split('\\t')] for l in lines]\n    \n    if reverse:\n        pairs=[list(reversed(p)) for p in pairs]\n    \n    input_lang=Lang(lang1)\n    output_lang=Lang(lang2)\n    \n    return input_lang,output_lang,pairs\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:23.652210Z","iopub.execute_input":"2023-10-15T13:50:23.652890Z","iopub.status.idle":"2023-10-15T13:50:23.659253Z","shell.execute_reply.started":"2023-10-15T13:50:23.652852Z","shell.execute_reply":"2023-10-15T13:50:23.658331Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH = 10\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s \",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\ndef filterPair(p):\n    return len(p[0].split(' '))<MAX_LENGTH and len(p[1].split(' '))<MAX_LENGTH #and p[1].startswith(eng_prefixes)\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:24.442155Z","iopub.execute_input":"2023-10-15T13:50:24.442792Z","iopub.status.idle":"2023-10-15T13:50:24.448515Z","shell.execute_reply.started":"2023-10-15T13:50:24.442747Z","shell.execute_reply":"2023-10-15T13:50:24.447591Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def prepareData(data,lang1,lang2,reverse=False):\n    print('Reading lines...')\n    lines=[]\n    for e_sent,f_sent in zip(data['cs_query'],data['en_query']):\n        both_sent=e_sent+'\\t'+f_sent\n        lines.append(both_sent)\n    input_lang,output_lang,pairs=readLangs(lines,lang1,lang2,reverse)\n    print(f'Read {len(pairs)} sentence pairs')\n    pairs=filterPairs(pairs)\n    print(f'Trimmed to {len(pairs)} sentence pairs')\n    print('Counting words')\n    \n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print('Counted words :')\n    print(input_lang.name,input_lang.n_words)\n    print(output_lang.name,output_lang.n_words)\n    return input_lang,output_lang,pairs\ninput_lang,output_lang,pairs=prepareData(data,'eng','Hinglish',True)\nprint(random.choice(pairs))","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:25.292583Z","iopub.execute_input":"2023-10-15T13:50:25.292944Z","iopub.status.idle":"2023-10-15T13:50:26.684487Z","shell.execute_reply.started":"2023-10-15T13:50:25.292918Z","shell.execute_reply":"2023-10-15T13:50:26.683416Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Reading lines...\nPreparing Vocabulary.......\nRead 50000 sentence pairs\nTrimmed to 27839 sentence pairs\nCounting words\nCounted words :\neng 5971\nHinglish 6393\n['networking parties happening this weekend', 'is weekend hone wale networking parties']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        output, hidden = self.gru(embedded)\n        return output, hidden","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:29.422965Z","iopub.execute_input":"2023-10-15T13:50:29.423581Z","iopub.status.idle":"2023-10-15T13:50:29.429075Z","shell.execute_reply.started":"2023-10-15T13:50:29.423550Z","shell.execute_reply":"2023-10-15T13:50:29.428059Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    \n    def __init__(self,hidden_size,output_size):\n        super(DecoderRNN,self).__init__()\n        self.embedding = nn.Embedding(output_size,hidden_size)\n        self.gru = nn.GRU(hidden_size,hidden_size,batch_first=True)\n        self.out = nn.Linear(hidden_size,output_size)\n    \n    def forward(self,encoder_outputs,encoder_hiddens,target_tensor=None):\n        batch_size=encoder_output_size(0)\n        decoder_input=torch.empty(batch_size,1,dtype=torch.long,device=device).fill_(SOS_token)\n        decoder_hidden=encoder_hidden\n        decoder_output=[]\n        \n        for i in range(MAX_LENGTH):\n            decoder_output,decoder_hidden=self.forward_step(decoder_input,decoder_hidden)\n            decoder_output.append(decoder_output)\n            \n            if target_tensor is not None:\n                decoder_input = target_tensor[:,i].unsqueeze(1)\n            else:\n                _,topi=decoder_output.topk(1)\n                decoder_input=topi.squeeze(-1).detach()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:30.386187Z","iopub.execute_input":"2023-10-15T13:50:30.386498Z","iopub.status.idle":"2023-10-15T13:50:30.394771Z","shell.execute_reply.started":"2023-10-15T13:50:30.386473Z","shell.execute_reply":"2023-10-15T13:50:30.393382Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Attentions ","metadata":{}},{"cell_type":"code","source":"#attention 1.\nclass BahdanauAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super(BahdanauAttention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze(2).unsqueeze(1)\n        \n        weights = F.softmax(scores, dim=-1)\n        context = torch.bmm(weights, keys)\n\n        return context, weights\n\n    def forward_inference(self, query, keys,):\n        print(20*'-',' Attention Inference start ',20*'-')\n        print('Query : ',query.shape)\n        print('Keys : ',keys.shape)\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        print('Scores : ',scores.shape)\n        scores = scores.squeeze(2).unsqueeze(1)\n        print('Scores squeeze(2) :',scores.squeeze(2).shape)\n        print('scores.squeeze(2).unsqueeze(1) : ',scores.squeeze(2).unsqueeze(1).shape)\n        \n        weights = F.softmax(scores, dim=-1)\n        print('Weights : [Softmax(scores)] : ',weights.shape)\n        context = torch.bmm(weights, keys)\n        print('Context : [batched-Matrix Mutliplication(weights, keys)] :',context.shape)\n        print('Attn Weight shape :',weights.shape)\n        print(20*'-',' Attention Inference End ',20*'-')\n        return context, weights\n# Attention 2\n\nclass DotProductAttentionLinear(nn.Module):\n    def __init__(self, hidden_size):\n        super(DotProductAttentionLinear, self).__init__()\n\n        # Linear transformations for query, key, and value\n        self.query_linear = nn.Linear(hidden_size, hidden_size)\n        self.key_linear = nn.Linear(hidden_size, hidden_size)\n        self.value_linear = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, query, keys, values, mask=None):\n        # Linear transformations of query, key, and value\n        query = self.query_linear(query)\n        keys = self.key_linear(keys)\n        values = self.value_linear(values)\n        # Calculate dot products\n        dot_products = torch.bmm(query, keys.transpose(1, 2))\n\n        # Apply mask (if provided)\n        if mask is not None:\n            dot_products.masked_fill_(mask, float('-inf'))\n\n        # Apply softmax to calculate attention weights\n        attention_weights = torch.nn.functional.softmax(dot_products, dim=-1)\n\n        # Calculate the weighted sum of values\n        context = torch.bmm(attention_weights, values)\n\n        return context, attention_weights\n#Attention 3\nclass SelfAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super(SelfAttention, self).__init__()\n\n        self.hidden_size =hidden_size\n\n        # Linear transformations for queries, keys, and values\n        self.q_linear = nn.Linear(hidden_size, hidden_size)\n        self.k_linear = nn.Linear(hidden_size, hidden_size)\n        self.v_linear = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, query, key, value, mask=None):\n        # Linear transformations\n        Q = self.q_linear(query)\n        K = self.k_linear(key)\n        V = self.v_linear(value)\n\n        # Scaled Dot-Product Attention\n        scores = torch.matmul(Q, K.permute(0, 2, 1)) / torch.sqrt(torch.tensor(self.hidden_size, dtype=torch.float32))\n\n\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n\n        attention = F.softmax(scores, dim=-1)\n        output = torch.matmul(attention, V)\n\n        return output, attention\n#Attention 4\nclass LocationBasedAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super(LocationBasedAttention, self).__init__()\n        self.Wq = nn.Linear(hidden_size, hidden_size)\n        self.Wk = nn.Linear(hidden_size, hidden_size)\n        self.Wv = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, query, keys):\n        # Linear transformations\n        q = self.Wq(query)\n        k = self.Wk(keys)\n        v = self.Wv(keys)\n\n        # Calculate attention scores (typically position-based)\n        scores = torch.matmul(q, k.transpose(1, 2))\n\n        # Apply softmax to obtain attention weights\n        weights = torch.nn.functional.softmax(scores, dim=-1)\n\n        # Compute the context vector based on attention weights\n        context = torch.matmul(weights, v)\n\n        return context, weights\n#attention 5\nclass GlobalAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super(GlobalAttention, self).__init__()\n        self.Wq = nn.Linear(hidden_size, hidden_size)\n        self.Wk = nn.Linear(hidden_size, hidden_size)\n        self.Wv = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, query, keys):\n        # Linear transformations\n        q = self.Wq(query)\n        k = self.Wk(keys)\n        v = self.Wv(keys)\n\n        # Calculate attention scores (global attention)\n        scores = torch.matmul(q, k.transpose(1, 2))\n\n        # Apply softmax to obtain attention weights\n        weights = torch.nn.functional.softmax(scores, dim=-1)\n\n        # Compute the context vector based on attention weights\n        context = torch.matmul(weights, v)\n\n        return context, weights","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:33.074186Z","iopub.execute_input":"2023-10-15T13:50:33.074574Z","iopub.status.idle":"2023-10-15T13:50:33.093343Z","shell.execute_reply.started":"2023-10-15T13:50:33.074546Z","shell.execute_reply":"2023-10-15T13:50:33.091801Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size,attention, dropout_p=0.1):\n        super(AttnDecoderRNN, self).__init__()\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.attention_name=attention\n        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.dropout = nn.Dropout(dropout_p)\n        if self.attention_name=='BahdanauAttention':\n            self.attention = BahdanauAttention(hidden_size)\n        elif self.attention_name=='DotProductAttentionLinear':\n            self.attention=DotProductAttentionLinear(hidden_size)\n        elif self.attention_name =='SelfAttention':\n            self.attention=SelfAttention(hidden_size)\n        elif self.attention_name == 'LocationBasedAttention':\n            self.attention=LocationBasedAttention(hidden_size)\n        elif self.attention_name == 'GlobalAttention':\n            self.attention=GlobalAttention(hidden_size)\n        else:\n            print('Error choose Correct Attention')\n            \n            \n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n        attentions = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            decoder_outputs.append(decoder_output)\n            attentions.append(attn_weights)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        attentions = torch.cat(attentions, dim=1)\n\n        return decoder_outputs, decoder_hidden, attentions\n\n    def forward_step(self, input, hidden, encoder_outputs):\n        embedded =  self.dropout(self.embedding(input))\n        \n        query = hidden.permute(1, 0, 2)\n        \n        if self.attention_name=='BahdanauAttention':\n            context, attn_weights = self.attention(query, encoder_outputs)\n        elif self.attention_name=='DotProductAttentionLinear':\n            context, attn_weights = self.attention(query, encoder_outputs,encoder_outputs)\n        elif self.attention_name=='SelfAttention':\n            context, attn_weights = self.attention(query, encoder_outputs,encoder_outputs)\n        elif self.attention_name== 'LocationBasedAttention':\n            context, attn_weights = self.attention(query, encoder_outputs)\n        elif self.attention_name == 'GlobalAttention':\n            context, attn_weights = self.attention(query, encoder_outputs)\n        else:\n            print('Error choose Correct Attention')\n            \n        input_gru = torch.cat((embedded, context), dim=2)\n        output, hidden = self.gru(input_gru, hidden)\n        output = self.out(output)\n\n        return output, hidden, attn_weights\n    def forward_step_attention_inference(self, input, hidden, encoder_outputs):\n        print(20*'-',' Forward Step Inference start',20*'-')\n        embedded =  self.dropout(self.embedding(input))\n        print('Embedding shape :',embedded.shape)\n        query = hidden.permute(1, 0, 2)\n        context, attn_weights = self.attention.forward_inference(query, encoder_outputs)\n        input_gru = torch.cat((embedded, context), dim=2)\n        print('Input to the Gru Concatenation of the embedded and context on dim 2 :',input_gru.shape)\n        output, hidden = self.gru(input_gru, hidden)\n        print('Output :',output.shape)\n        print('Hidden :',hidden.shape)\n        output = self.out(output)\n        print('Final Linear Ouptut .shape ',output.shape)\n        print(20*'-',' Forward Step Inference End',20*'-')\n        return output, hidden, attn_weights\n    def inference_shape(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        \n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n        attentions = []\n        print(50*'-','Forward Method begin',50*'-')\n        print('Batch Size : ',batch_size)\n        print('decoder Input shape:',decoder_input.shape)\n        #print('decoder Input : ',decoder_input)\n        print('decoder Hidden :',decoder_hidden.shape)\n        print(20*'-','Decoder Mapping Start ',20*'-')\n        for i in range(MAX_LENGTH):\n            print(f'Iteration : [{MAX_LENGTH+1}/{i+1}]  --->  Iteration : {i+1}')\n            decoder_output, decoder_hidden, attn_weights = self.forward_step_attention_inference(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            decoder_outputs.append(decoder_output)\n            attentions.append(attn_weights)\n            print(f'Iteration {i+1} | Deocder output shape :{decoder_output.shape}: Lenght of List of Decoder Output : ',len(decoder_outputs))\n            print(f'Iteration {i+1} | Attention Weights : ',attn_weights.shape)\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n                print('Teacher Forcing | Feed the target as the next input :',target_tensor[:, i].unsqueeze(1).shape)\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n                print('Without teacher forcing: use its own predictions as the next input : ',decoder_output.topk(1).shape)\n            print(20*'-','Decoder Mapping End',20*'-')\n        print('*********Forward Step Function******')\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        print('Final Decoder output concatenation : ',decoder_outputs.shape)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        print('Softmax Applying Decoder outputs : ',decoder_outputs.shape)\n        attentions = torch.cat(attentions, dim=1)\n        print('Attention concatenation to dim : 1',attentions.shape)\n        print(50*'-','Forward Method End',50*'-')\n        return decoder_outputs, decoder_hidden, attentions","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:35.767641Z","iopub.execute_input":"2023-10-15T13:50:35.768041Z","iopub.status.idle":"2023-10-15T13:50:35.788123Z","shell.execute_reply.started":"2023-10-15T13:50:35.768013Z","shell.execute_reply":"2023-10-15T13:50:35.786891Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def indexesFromSentence(lang, sentence):\n    words=sentence.split(' ')\n    return [lang.word2index.get(word,UNK_token) for word in words]\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)\n\ndef get_dataloader(batch_size):\n    input_lang, output_lang, pairs = prepareData(data,'eng', 'Hinglish', True)\n\n    n = len(pairs)\n    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n\n    for idx, (inp, tgt) in enumerate(pairs):\n        inp_ids = indexesFromSentence(input_lang, inp)\n        tgt_ids = indexesFromSentence(output_lang, tgt)\n        inp_ids.append(EOS_token)\n        tgt_ids.append(EOS_token)\n        input_ids[idx, :len(inp_ids)] = inp_ids\n        target_ids[idx, :len(tgt_ids)] = tgt_ids\n\n    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n                               torch.LongTensor(target_ids).to(device))\n\n    train_sampler = RandomSampler(train_data)\n    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n    return input_lang, output_lang, train_dataloader\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:37.374355Z","iopub.execute_input":"2023-10-15T13:50:37.374737Z","iopub.status.idle":"2023-10-15T13:50:37.382837Z","shell.execute_reply.started":"2023-10-15T13:50:37.374707Z","shell.execute_reply":"2023-10-15T13:50:37.381785Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion,inference):\n\n    total_loss = 0\n    for data in dataloader:\n        input_tensor, target_tensor = data\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n\n        loss = criterion(\n            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n            target_tensor.view(-1)\n        )\n        loss.backward()\n        \n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n        total_loss += loss.item()\n        \n    return total_loss / len(dataloader)\ndef train_epoch_inference(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion,inference):\n    total_loss = 0\n    if inference:\n            for data in dataloader:\n                input_tensor, target_tensor = data\n\n                encoder_optimizer.zero_grad()\n                decoder_optimizer.zero_grad()\n\n                encoder_outputs, encoder_hidden = encoder(input_tensor)\n                decoder_outputs, _, _ = decoder.inference_shape(encoder_outputs, encoder_hidden, target_tensor)\n\n                loss = criterion(\n                    decoder_outputs.view(-1, decoder_outputs.size(-1)),\n                    target_tensor.view(-1)\n                )\n                loss.backward()\n\n                encoder_optimizer.step()\n                decoder_optimizer.step()\n\n                total_loss += loss.item()\n                print('Input Shape : ',input_tensor.shape)\n                print('Output Shape :',target_tensor.shape)\n                print('Encoder Outputs : ',encoder_outputs.shape)\n                print('Encoder Hidden :',encoder_hidden.shape)\n                print('Decoder _outputs :',decoder_outputs.shape)\n                print('Loss->Decoder.shape :',decoder_outputs.view(-1, decoder_outputs.size(-1)).shape)\n                print('Loss-> Target shape :',target_tensor.view(-1).shape)\n                print('Loss : ',loss.item())\n                break\n    return total_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:39.101903Z","iopub.execute_input":"2023-10-15T13:50:39.102211Z","iopub.status.idle":"2023-10-15T13:50:39.111392Z","shell.execute_reply.started":"2023-10-15T13:50:39.102185Z","shell.execute_reply":"2023-10-15T13:50:39.110462Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:40.907087Z","iopub.execute_input":"2023-10-15T13:50:40.907415Z","iopub.status.idle":"2023-10-15T13:50:40.913389Z","shell.execute_reply.started":"2023-10-15T13:50:40.907387Z","shell.execute_reply":"2023-10-15T13:50:40.912400Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n               print_every=100, plot_every=100,inference=False):\n    if inference:\n        print('Inference Start :Set to Epoch : 1 ')\n        print(time.time())\n        n_epochs=1\n        \n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n    criterion = nn.NLLLoss()\n    \n    for epoch in range(1, n_epochs + 1):\n        if inference :\n            train_epoch_inference(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,inference)\n            print('Inference End ')\n            return \n        else:\n            loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,inference)\n            print_loss_total += loss\n            plot_loss_total += loss\n\n            if epoch % print_every == 0:\n                print_loss_avg = print_loss_total / print_every\n                print_loss_total = 0\n                print(f'Time : -{timeSince(start, epoch / n_epochs)} | Epoch : {epoch} | Complete : {epoch / n_epochs * 100}%  | Average Loss :{print_loss_avg}')\n                \n\n            if epoch % plot_every == 0:\n                plot_loss_avg = plot_loss_total / plot_every\n                plot_losses.append(plot_loss_avg)\n                plot_loss_total = 0\n    return plot_losses","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:41.512539Z","iopub.execute_input":"2023-10-15T13:50:41.513144Z","iopub.status.idle":"2023-10-15T13:50:41.520530Z","shell.execute_reply.started":"2023-10-15T13:50:41.513117Z","shell.execute_reply":"2023-10-15T13:50:41.519521Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:43.304547Z","iopub.execute_input":"2023-10-15T13:50:43.305489Z","iopub.status.idle":"2023-10-15T13:50:43.311445Z","shell.execute_reply.started":"2023-10-15T13:50:43.305448Z","shell.execute_reply":"2023-10-15T13:50:43.310531Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n\n        _, topi = decoder_outputs.topk(1)\n        decoded_ids = topi.squeeze()\n\n        decoded_words = []\n        for idx in decoded_ids:\n            if idx.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            decoded_words.append(output_lang.index2word[idx.item()])\n    return decoded_words, decoder_attn\ndef evaluateRandomly(encoder, decoder, n=100):\n    predictions = {\n        'actual': [],\n        'predict': [],\n        'target': []\n    }\n\n    for i in range(n):\n        pair = random.choice(pairs)\n\n        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n        output_sentence = ' '.join(output_words)\n\n        predictions['actual'].append(pair[0])\n        predictions['target'].append(pair[1])\n        predictions['predict'].append(output_sentence)\n        if i<=5:\n            print('>', pair[0])\n            print('=', pair[1])\n            print('<', output_sentence)\n            print('')\n    return predictions\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:44.210154Z","iopub.execute_input":"2023-10-15T13:50:44.210486Z","iopub.status.idle":"2023-10-15T13:50:44.217977Z","shell.execute_reply.started":"2023-10-15T13:50:44.210461Z","shell.execute_reply":"2023-10-15T13:50:44.217003Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"hidden_size = 128\nbatch_size = 32\ninput_lang, output_lang, train_dataloader = get_dataloader(batch_size)\nprint('Initializing Attentions ......')\nAtten_losses={}\nattentions={'bha':'BahdanauAttention','dpa':'DotProductAttentionLinear',\n            'sa':'SelfAttention','lba':'LocationBasedAttention',\n            'gba':'GlobalAttention'}\nmap_prediction={}\nfor keys,value in attentions.items():\n    print(f'Training with : {value}')\n    encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n    decoder = AttnDecoderRNN(hidden_size, output_lang.n_words,attention=value).to(device)\n    print('Training Start..')\n    losses=train(train_dataloader, encoder, decoder, 50, print_every=5, plot_every=5,inference=False)\n    Atten_losses[keys]=losses\n    print('Training End..')\n    print(f'{value} - Evaluation ....')\n    encoder.eval()\n    decoder.eval()\n    predictions=evaluateRandomly(encoder, decoder)\n    map_prediction[value]=predictions\n    print(f'{value} Evaluation End ...')\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T13:50:59.415971Z","iopub.execute_input":"2023-10-15T13:50:59.416294Z","iopub.status.idle":"2023-10-15T15:02:34.053977Z","shell.execute_reply.started":"2023-10-15T13:50:59.416268Z","shell.execute_reply":"2023-10-15T15:02:34.052955Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Reading lines...\nPreparing Vocabulary.......\nRead 50000 sentence pairs\nTrimmed to 27839 sentence pairs\nCounting words\nCounted words :\neng 5971\nHinglish 6393\nInitializing Attentions ......\nTraining with : BahdanauAttention\nTraining Start..\nTime : -1m 22s (- 12m 25s) | Epoch : 5 | Complete : 10.0%  | Average Loss :1.5017988410557823\nTime : -2m 43s (- 10m 52s) | Epoch : 10 | Complete : 20.0%  | Average Loss :0.5245570382578619\nTime : -4m 2s (- 9m 26s) | Epoch : 15 | Complete : 30.0%  | Average Loss :0.2804525253587756\nTime : -5m 22s (- 8m 4s) | Epoch : 20 | Complete : 40.0%  | Average Loss :0.1875778607373265\nTime : -6m 43s (- 6m 43s) | Epoch : 25 | Complete : 50.0%  | Average Loss :0.1412806620226167\nTime : -8m 2s (- 5m 21s) | Epoch : 30 | Complete : 60.0%  | Average Loss :0.11385311123369068\nTime : -9m 21s (- 4m 0s) | Epoch : 35 | Complete : 70.0%  | Average Loss :0.09637685755674524\nTime : -10m 41s (- 2m 40s) | Epoch : 40 | Complete : 80.0%  | Average Loss :0.08406569045293948\nTime : -12m 0s (- 1m 20s) | Epoch : 45 | Complete : 90.0%  | Average Loss :0.0747161631388911\nTime : -13m 20s (- 0m 0s) | Epoch : 50 | Complete : 100.0%  | Average Loss :0.06825690384911395\nTraining End..\nBahdanauAttention - Evaluation ....\n> turn on my stopwatch\n= mera stopwatch on karo\n< mera stopwatch par chalu mera chalu kare <EOS>\n\n> tell me the weather  .\n= mujhe mausam batao  .\n< mujhe mausam batao  . <EOS>\n\n> what ' s the weekend forecast at home\n= ghar par weekend forecast kya hai\n< ghar par weekend forecast kya hai <EOS>\n\n> i want to listen to spice girls  .\n= me spice girls ko sunna chahta hu  .\n< me spice girls ko sunna chahta hu  . <EOS>\n\n> give me the weather report for germany\n= mujhe germany ke liye weather report do\n< mujhe germany ke liye weather report do <EOS>\n\n> snooze this alarm for 5 minutes\n= is alarm ko 5 minutes ke liye snooze kare\n< is alarm set 5 for 5 minutes ke liye snooze\n\nBahdanauAttention Evaluation End ...\n\nTraining with : DotProductAttentionLinear\nTraining Start..\nTime : -1m 20s (- 12m 3s) | Epoch : 5 | Complete : 10.0%  | Average Loss :1.6499552545739316\nTime : -2m 40s (- 10m 43s) | Epoch : 10 | Complete : 20.0%  | Average Loss :0.7175377040416345\nTime : -4m 1s (- 9m 23s) | Epoch : 15 | Complete : 30.0%  | Average Loss :0.4423031785399064\nTime : -5m 22s (- 8m 3s) | Epoch : 20 | Complete : 40.0%  | Average Loss :0.3068555179683642\nTime : -6m 42s (- 6m 42s) | Epoch : 25 | Complete : 50.0%  | Average Loss :0.23443173539707032\nTime : -8m 3s (- 5m 22s) | Epoch : 30 | Complete : 60.0%  | Average Loss :0.1896326133386157\nTime : -9m 23s (- 4m 1s) | Epoch : 35 | Complete : 70.0%  | Average Loss :0.15876933824827616\nTime : -10m 43s (- 2m 40s) | Epoch : 40 | Complete : 80.0%  | Average Loss :0.14716621756468012\nTime : -12m 4s (- 1m 20s) | Epoch : 45 | Complete : 90.0%  | Average Loss :0.12686318353674877\nTime : -13m 24s (- 0m 0s) | Epoch : 50 | Complete : 100.0%  | Average Loss :0.11601538169743686\nTraining End..\nDotProductAttentionLinear - Evaluation ....\n> how hot will it be this afternoon  ?\n= aaj dopahar kitni garmi hone wali hai  ?\n< aaj dopahar kitni garmi hone wali hai  ? <EOS>\n\n> what is the weather all week  ?\n= haftey ka weather kya hai\n< hafte ke liye weather kya hai <EOS>\n\n> how long would it take to drive to seattle\n= seattle tak drive karne me kitna waqt lagega\n< seattle tak drive karne me kitna waqt lagega <EOS>\n\n> erase that coffee timer\n= us coffee timer ko erase kare\n< us coffee timer ko phirse for 15 emoji <EOS>\n\n> begin two timers please\n= do timers shuru kare please\n< please do timers shuru kare <EOS>\n\n> how warm is it in mumbai in degree c\n= mumbai me kitna degree c garm hai\n< mumbai me kitna degree c garm hai <EOS>\n\nDotProductAttentionLinear Evaluation End ...\n\nTraining with : SelfAttention\nTraining Start..\nTime : -1m 33s (- 13m 57s) | Epoch : 5 | Complete : 10.0%  | Average Loss :1.5755520448876523\nTime : -3m 5s (- 12m 23s) | Epoch : 10 | Complete : 20.0%  | Average Loss :0.5811758377634245\nTime : -4m 38s (- 10m 48s) | Epoch : 15 | Complete : 30.0%  | Average Loss :0.33422976213967664\nTime : -6m 11s (- 9m 17s) | Epoch : 20 | Complete : 40.0%  | Average Loss :0.2339342111503256\nTime : -7m 44s (- 7m 44s) | Epoch : 25 | Complete : 50.0%  | Average Loss :0.1827872390017427\nTime : -9m 17s (- 6m 11s) | Epoch : 30 | Complete : 60.0%  | Average Loss :0.1524035315266971\nTime : -10m 50s (- 4m 38s) | Epoch : 35 | Complete : 70.0%  | Average Loss :0.13185824046446673\nTime : -12m 22s (- 3m 5s) | Epoch : 40 | Complete : 80.0%  | Average Loss :0.11806045577186963\nTime : -13m 55s (- 1m 32s) | Epoch : 45 | Complete : 90.0%  | Average Loss :0.10711272840356005\nTime : -15m 28s (- 0m 0s) | Epoch : 50 | Complete : 100.0%  | Average Loss :0.09870733171701432\nTraining End..\nSelfAttention - Evaluation ....\n> what time does the sun rise today\n= aaj kitne bajhe sun set hoga\n< aaj kitne bajhe sun set hoga <EOS>\n\n> go ahead and stop this timer\n= go ahead aur is timer ko stop kare\n< go ahead aur is timer ko stop kare aur bolo\n\n> will it rain tomorrow  ?\n= kya kal barish hone wali hai  ?\n< kya kal baarish hogi  ? <EOS>\n\n> can you reply back to the message\n= kya aap message ko wapas reply karsakte hai\n< kya aap message ko wapas reply karsakte hai <EOS>\n\n> continue timer\n= timer ko continue karo\n< timer ko abhi shuru 1 ke liye cardio shuru hogi\n\n> why is the traffic at a dead stop\n= traffic kab tak dead stop par hai\n< traffic kab tak dead karne ke liye hai <EOS>\n\nSelfAttention Evaluation End ...\n\nTraining with : LocationBasedAttention\nTraining Start..\nTime : -1m 27s (- 13m 6s) | Epoch : 5 | Complete : 10.0%  | Average Loss :1.7135327272305545\nTime : -2m 55s (- 11m 41s) | Epoch : 10 | Complete : 20.0%  | Average Loss :0.7753309010637217\nTime : -4m 23s (- 10m 15s) | Epoch : 15 | Complete : 30.0%  | Average Loss :0.4941365103063912\nTime : -5m 51s (- 8m 46s) | Epoch : 20 | Complete : 40.0%  | Average Loss :0.35189347249338\nTime : -7m 19s (- 7m 19s) | Epoch : 25 | Complete : 50.0%  | Average Loss :0.27523907405377807\nTime : -8m 47s (- 5m 51s) | Epoch : 30 | Complete : 60.0%  | Average Loss :0.23555362363313806\nTime : -10m 16s (- 4m 24s) | Epoch : 35 | Complete : 70.0%  | Average Loss :0.1966180402537187\nTime : -11m 44s (- 2m 56s) | Epoch : 40 | Complete : 80.0%  | Average Loss :0.17638430273909678\nTime : -13m 12s (- 1m 28s) | Epoch : 45 | Complete : 90.0%  | Average Loss :0.15351702101014814\nTime : -14m 40s (- 0m 0s) | Epoch : 50 | Complete : 100.0%  | Average Loss :0.16161948819013164\nTraining End..\nLocationBasedAttention - Evaluation ....\n> are there any thunderstorms in my area\n= kya mere area me koi thunderstorms hai\n< kya mere area me koi heavy hai <EOS>\n\n> please give me driving directions home\n= please mujhe ghar ke driving directions batayen\n< please mujhe orlando ke liye driving directions batayen <EOS>\n\n> new timer for 1 minute  .\n= 1 minute ke liye naya timer  .\n< 1 minute ke liye naya timer  . <EOS>\n\n> repeat this song\n= is gaaney ko repeat kare\n< is gaaney ko repeat kare  . <EOS>\n\n> set an alarm for 1 pm\n= 1 pm ke liye alarm set kare\n< 1 pm ke liye alarm set kare <EOS>\n\n> send a response to jill\n= jill ko ek response bhejen\n< jill ko ek response bhejen <EOS>\n\nLocationBasedAttention Evaluation End ...\n\nTraining with : GlobalAttention\nTraining Start..\nTime : -1m 28s (- 13m 14s) | Epoch : 5 | Complete : 10.0%  | Average Loss :1.6923792417159025\nTime : -2m 56s (- 11m 47s) | Epoch : 10 | Complete : 20.0%  | Average Loss :0.7824991492978457\nTime : -4m 25s (- 10m 18s) | Epoch : 15 | Complete : 30.0%  | Average Loss :0.5346449970411159\nTime : -5m 51s (- 8m 47s) | Epoch : 20 | Complete : 40.0%  | Average Loss :0.41028566019288426\nTime : -7m 19s (- 7m 19s) | Epoch : 25 | Complete : 50.0%  | Average Loss :0.34080402856928177\nTime : -8m 46s (- 5m 51s) | Epoch : 30 | Complete : 60.0%  | Average Loss :0.3237175738160637\nTime : -10m 14s (- 4m 23s) | Epoch : 35 | Complete : 70.0%  | Average Loss :0.276754873987587\nTime : -11m 41s (- 2m 55s) | Epoch : 40 | Complete : 80.0%  | Average Loss :0.26616784169071017\nTime : -13m 8s (- 1m 27s) | Epoch : 45 | Complete : 90.0%  | Average Loss :0.23523581449156522\nTime : -14m 35s (- 0m 0s) | Epoch : 50 | Complete : 100.0%  | Average Loss :0.22402422708684\nTraining End..\nGlobalAttention - Evaluation ....\n> replay the previous song please\n= pichla song reply kare please\n< pichla gaana replay kare please <EOS>\n\n> will it rain today\n= kya aj barish hogi\n< kya aaj baarish hogi <EOS>\n\n> was there construction on 820\n= kya 820 par construction chal raha he\n< kya par construction ka bacha hai <EOS>\n\n> alarm for 2 minutes\n= do minute ke liye alarm\n< 2 minutes ke liye alarm , <EOS>\n\n> skip the hip hop music\n= hip hop music ko skip kare\n< hip hop music ko skip kare <EOS>\n\n> events outdoors\n= outdoors mei events hai\n< outdoors me events ke baare me events <EOS>\n\nGlobalAttention Evaluation End ...\n\n","output_type":"stream"}]},{"cell_type":"code","source":"loss=pd.DataFrame(Atten_losses,columns=Atten_losses.keys())\nloss.to_csv('Attention_losses.csv',index=None)\nloss.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T15:11:26.545447Z","iopub.execute_input":"2023-10-15T15:11:26.546121Z","iopub.status.idle":"2023-10-15T15:11:26.563751Z","shell.execute_reply.started":"2023-10-15T15:11:26.546090Z","shell.execute_reply":"2023-10-15T15:11:26.562782Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"        bha       dpa        sa       lba       gba\n0  1.501799  1.649955  1.575552  1.713533  1.692379\n1  0.524557  0.717538  0.581176  0.775331  0.782499\n2  0.280453  0.442303  0.334230  0.494137  0.534645\n3  0.187578  0.306856  0.233934  0.351893  0.410286\n4  0.141281  0.234432  0.182787  0.275239  0.340804","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bha</th>\n      <th>dpa</th>\n      <th>sa</th>\n      <th>lba</th>\n      <th>gba</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.501799</td>\n      <td>1.649955</td>\n      <td>1.575552</td>\n      <td>1.713533</td>\n      <td>1.692379</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.524557</td>\n      <td>0.717538</td>\n      <td>0.581176</td>\n      <td>0.775331</td>\n      <td>0.782499</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.280453</td>\n      <td>0.442303</td>\n      <td>0.334230</td>\n      <td>0.494137</td>\n      <td>0.534645</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.187578</td>\n      <td>0.306856</td>\n      <td>0.233934</td>\n      <td>0.351893</td>\n      <td>0.410286</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.141281</td>\n      <td>0.234432</td>\n      <td>0.182787</td>\n      <td>0.275239</td>\n      <td>0.340804</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"blu_score={}\nfrom nltk.translate.bleu_score import SmoothingFunction, corpus_bleu\n# Create a dictionary to store the data frames\nattention_data_frames = {}\n# Assuming map_prediction is your dictionary\nfor attention, predictions in map_prediction.items():\n    df = pd.DataFrame(predictions)\n    # Store the data frame in the dictionary with a short name\n    attention_data_frames[attention] = df\n    \nfor key,values in attention_data_frames.items():\n    print('Attention : ',key)\n    references = values['target']\n    hypotheses = values['predict']\n    # Calculate BLEU scores for the entire batch\n    bleu_scores = corpus_bleu(references, hypotheses)\n    # Print the BLEU scores\n    print(\"BLEU Scores: \", bleu_scores)\n    blu_score[keys]=bleu_scores\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T15:13:38.592303Z","iopub.execute_input":"2023-10-15T15:13:38.592690Z","iopub.status.idle":"2023-10-15T15:13:39.831660Z","shell.execute_reply.started":"2023-10-15T15:13:38.592660Z","shell.execute_reply":"2023-10-15T15:13:39.830653Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Attention :  BahdanauAttention\nBLEU Scores:  0.7684297726002483\n\nAttention :  DotProductAttentionLinear\nBLEU Scores:  0.7665481564327498\n\nAttention :  SelfAttention\nBLEU Scores:  0.7617910632731427\n\nAttention :  LocationBasedAttention\nBLEU Scores:  0.7703729490539172\n\nAttention :  GlobalAttention\nBLEU Scores:  0.7709167710280911\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Extract the language pairs and scores as separate lists\nattentions = list(blu_score.keys())\nscores = list(blu_score.values())\n\n# Create the bar chart\nplt.bar(attentions, scores)\n\n# Add labels and a title\nplt.xlabel('Attentions')\nplt.ylabel('BLEU Score')\nplt.title('BLEU Scores for Different Attentions')\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T15:17:01.627950Z","iopub.execute_input":"2023-10-15T15:17:01.628293Z","iopub.status.idle":"2023-10-15T15:17:01.678286Z","shell.execute_reply.started":"2023-10-15T15:17:01.628267Z","shell.execute_reply":"2023-10-15T15:17:01.676899Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Training Model With Attention (that has best Bleu Score)","metadata":{}},{"cell_type":"code","source":"hidden_size = 128\nbatch_size = 32\ninput_lang, output_lang, train_dataloader = get_dataloader(batch_size)\nprint('Initializing Attentions ......')\nAtten_losses={}\nattentions={'gba':'GlobalAttention'}\nmap_prediction={}\nfor keys,value in attentions.items():\n    print(f'Training with : {value}')\n    encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n    decoder = AttnDecoderRNN(hidden_size, output_lang.n_words,attention=value).to(device)\n    print('Training Start..')\n    losses=train(train_dataloader, encoder, decoder, 70, print_every=5, plot_every=5,inference=False)\n    Atten_losses[keys]=losses\n    print('Training End..')\n    print(f'{value} - Evaluation ....')\n    encoder.eval()\n    decoder.eval()\n    predictions=evaluateRandomly(encoder, decoder)\n    map_prediction[value]=predictions\n    print(f'{value} Evaluation End ...')\n    print('Saving the Model')\n    # Save the encoder model\n    torch.save(encoder.state_dict(), 'encoder_model.pt')\n    # Save the decoder model\n    torch.save(decoder.state_dict(), 'decoder_model.pt')\n    print('Model is Saved')\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-10-15T15:17:12.676332Z","iopub.execute_input":"2023-10-15T15:17:12.676698Z","iopub.status.idle":"2023-10-15T15:38:03.230305Z","shell.execute_reply.started":"2023-10-15T15:17:12.676670Z","shell.execute_reply":"2023-10-15T15:38:03.229220Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Reading lines...\nPreparing Vocabulary.......\nRead 50000 sentence pairs\nTrimmed to 27839 sentence pairs\nCounting words\nCounted words :\neng 5971\nHinglish 6393\nInitializing Attentions ......\nTraining with : GlobalAttention\nTraining Start..\nTime : -1m 30s (- 19m 31s) | Epoch : 5 | Complete : 7.142857142857142%  | Average Loss :1.6962527414025932\nTime : -2m 59s (- 17m 59s) | Epoch : 10 | Complete : 14.285714285714285%  | Average Loss :0.7954896988128793\nTime : -4m 29s (- 16m 28s) | Epoch : 15 | Complete : 21.428571428571427%  | Average Loss :0.5307124808533439\nTime : -5m 58s (- 14m 56s) | Epoch : 20 | Complete : 28.57142857142857%  | Average Loss :0.4200999793924134\nTime : -7m 27s (- 13m 26s) | Epoch : 25 | Complete : 35.714285714285715%  | Average Loss :0.33933049223203765\nTime : -8m 57s (- 11m 56s) | Epoch : 30 | Complete : 42.857142857142854%  | Average Loss :0.30316461343361045\nTime : -10m 26s (- 10m 26s) | Epoch : 35 | Complete : 50.0%  | Average Loss :0.2780036887166829\nTime : -11m 55s (- 8m 56s) | Epoch : 40 | Complete : 57.14285714285714%  | Average Loss :0.27174431070171556\nTime : -13m 24s (- 7m 26s) | Epoch : 45 | Complete : 64.28571428571429%  | Average Loss :0.23786462085171678\nTime : -14m 53s (- 5m 57s) | Epoch : 50 | Complete : 71.42857142857143%  | Average Loss :0.24758659591619997\nTime : -16m 21s (- 4m 27s) | Epoch : 55 | Complete : 78.57142857142857%  | Average Loss :0.24587032494360006\nTime : -17m 50s (- 2m 58s) | Epoch : 60 | Complete : 85.71428571428571%  | Average Loss :0.21836082195584802\nTime : -19m 19s (- 1m 29s) | Epoch : 65 | Complete : 92.85714285714286%  | Average Loss :0.21538948097790794\nTime : -20m 48s (- 0m 0s) | Epoch : 70 | Complete : 100.0%  | Average Loss :0.20912327834758265\nTraining End..\nGlobalAttention - Evaluation ....\n> what ' s the distance between paris and miami\n= paris aur miami ke beech kitna distance hai\n< paris aur miami ke beech kitna distance hai <EOS>\n\n> train rides in pennsylvania this weekend\n= is weekend pennsylvania mei train rides\n< is weekend pennsylvania mei train rides <EOS>\n\n> what is my timer set for\n= mera timer kis liye set hai\n< mere timer ke liye set kare <EOS>\n\n> play the next song on the album\n= album par agla song bajao\n< album par agle song ko shuffle kare <EOS>\n\n> display my afternoon alarms\n= mere afternoon ke alarms ko dikhao\n< mere dopahar ke out alarms dikhao <EOS>\n\n> message david to contact me\n= david ko message karo contact me\n< david ko message karo contact me <EOS>\n\nGlobalAttention Evaluation End ...\nSaving the Model\nModel is Saved\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}