{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "M8UHxrkLEAf8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "UNK_token=2\n",
        "class Lang:\n",
        "    def __init__(self,name):\n",
        "        self.name=name\n",
        "        self.word2index={}\n",
        "        self.word2count={}\n",
        "        self.index2word={0:'sos',1:'eos','unk':2}\n",
        "        self.n_words=2\n",
        "    def addSentence(self,sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self,word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word]=self.n_words\n",
        "            self.word2count[word]=1\n",
        "            self.index2word[self.n_words]=word\n",
        "            self.n_words+=1\n",
        "        else:\n",
        "            self.word2count[word]+=1\n",
        ""
      ],
      "metadata": {
        "id": "jfJMhfZXC1OO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_path='/content/drive/MyDrive/NMT_Model/encoder_model.pt'\n",
        "decoder_path='/content/drive/MyDrive/NMT_Model/decoder_model.pt'\n",
        "lang_path='/content/drive/MyDrive/NMT_Model/lang_instances.pkl'"
      ],
      "metadata": {
        "id": "xT5I9EbcD_aY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Load instances of your custom Lang class from the file\n",
        "with open(lang_path, 'rb') as file:\n",
        "    loaded_lang_instances = pickle.load(file)\n",
        "\n",
        "# Access individual instances by language\n",
        "english_lang_instance = loaded_lang_instances['english']\n",
        "hnglish_lang_instance = loaded_lang_instances['henglish']\n",
        "\n",
        "# Access more languages and instances as needed\n",
        "\n"
      ],
      "metadata": {
        "id": "LBoLMwq0Pw7u"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    #s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
        "    return s.strip()\n",
        ""
      ],
      "metadata": {
        "id": "Z6-wCsleEFMF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "YQiemxPBERAk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(GlobalAttention, self).__init__()\n",
        "        self.Wq = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Wk = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Wv = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        # Linear transformations\n",
        "        q = self.Wq(query)\n",
        "        k = self.Wk(keys)\n",
        "        v = self.Wv(keys)\n",
        "\n",
        "        # Calculate attention scores (global attention)\n",
        "        scores = torch.matmul(q, k.transpose(1, 2))\n",
        "\n",
        "        # Apply softmax to obtain attention weights\n",
        "        weights = torch.nn.functional.softmax(scores, dim=-1)\n",
        "\n",
        "        # Compute the context vector based on attention weights\n",
        "        context = torch.matmul(weights, v)\n",
        "\n",
        "        return context, weights"
      ],
      "metadata": {
        "id": "Cds2nEePER_m"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH=15"
      ],
      "metadata": {
        "id": "QaARZRlWElUO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size,attention, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention_name=attention\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        if self.attention_name == 'GlobalAttention':\n",
        "            self.attention=GlobalAttention(hidden_size)\n",
        "        else:\n",
        "            print('Error choose Correct Attention')\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "\n",
        "        if self.attention_name=='BahdanauAttention':\n",
        "            context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        elif self.attention_name=='DotProductAttentionLinear':\n",
        "            context, attn_weights = self.attention(query, encoder_outputs,encoder_outputs)\n",
        "        elif self.attention_name=='SelfAttention':\n",
        "            context, attn_weights = self.attention(query, encoder_outputs,encoder_outputs)\n",
        "        elif self.attention_name== 'LocationBasedAttention':\n",
        "            context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        elif self.attention_name == 'GlobalAttention':\n",
        "            context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        else:\n",
        "            print('Error choose Correct Attention')\n",
        "\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "gJnVeSP8EYS7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    words=sentence.split(' ')\n",
        "    return [lang.word2index.get(word,UNK_token) for word in words]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)"
      ],
      "metadata": {
        "id": "hWbBqwFXEvrG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn\n",
        "def evaluateRandomly(encoder, decoder, input_sentence,input_lang,output_lang):\n",
        "        output_words, _ = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        return output_sentence"
      ],
      "metadata": {
        "id": "Kh0VtqPhJYQ-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "value='GlobalAttention'\n",
        "encoder = EncoderRNN(english_lang_instance.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, hnglish_lang_instance.n_words,attention=value).to(device)\n",
        "learning_rate=0.001\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "criterion = nn.NLLLoss()\n",
        "# Load the trained model weights\n",
        "encoder.load_state_dict(torch.load(encoder_path))\n",
        "decoder.load_state_dict(torch.load(decoder_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jShibt-PJIu1",
        "outputId": "2b876e13-24e7-4cba-da77-13db700011e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  input_sentence=input('Enter Sentence in English : ')\n",
        "  if input_sentence=='Quit':\n",
        "    print('Bye Bye...')\n",
        "    break\n",
        "  #prediction\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "  predictions=evaluateRandomly(encoder, decoder,input_sentence,english_lang_instance,hnglish_lang_instance)\n",
        "  print('Output Sentence : ',predictions)\n",
        "  print()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5EHJk3iRIQ1",
        "outputId": "de4a5a6a-706d-4a71-d126-05c64f76e433"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Sentence in English : How Long it will be raining ?\n",
            "Output Sentence :  kya aaj baarish horahi hai  ? <EOS>\n",
            "\n",
            "Enter Sentence in English : play the top 10 songs of 1990\n",
            "Output Sentence :  1990 ke top 10 songs bajao <EOS>\n",
            "\n",
            "Enter Sentence in English : \tis it sunny today ?\n",
            "Output Sentence :  aaj sunny day hai  ? <EOS>\n",
            "\n",
            "Enter Sentence in English : Quit\n",
            "Bye Bye...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aNnu1HOqPD1g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}